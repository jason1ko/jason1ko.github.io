---
title: "Consultation 2"
date: 2025-03-01 23:50:00
categories: [Data Science Institute]
layout: post
---

{% include sidebar.html %}

<div class="main-content">

<body>


<div class="container-fluid main-container">




<div id="header">




</div>


<div id="consultation-2-repeated-measures-anova-and-multilevel-mediation-for-a-four-type-persuasion-study" class="section level1">
<h1>Consultation 2: Repeated-Measures ANOVA and Multilevel Mediation for
a Four-Type Persuasion Study</h1>
<div id="i.-clients-inquiry" class="section level2">
<h2>I. Client’s Inquiry</h2>
<div id="context" class="section level3">
<h3>1. Context</h3>
<p>The client seeks <strong>statistical consulting</strong> to (a)
choose appropriate analysis methods for their study and (b) potentially
outsource analyses if they are too difficult to perform
independently.</p>
</div>
<div id="key-questions" class="section level3">
<h3>2. Key Questions</h3>
<div id="q1.-appropriateness-of-h1-h2-analyses" class="section level4">
<h4>Q1. Appropriateness of H1 &amp; H2 Analyses</h4>
<ul>
<li><strong>Design:</strong> within-subjects (repeated measures);
<strong>all participants</strong> experienced <strong>four persuasion
types</strong> (A, B, C, D).</li>
<li><strong>Sample size:</strong> <strong>n = 286</strong>.</li>
<li><strong>Assumptions:</strong> <strong>normality violated</strong>,
<strong>sphericity violated</strong>.</li>
<li><strong>Question:</strong> Is it acceptable to use <strong>One-Way
Repeated Measures ANOVA</strong> with
<strong>Greenhouse–Geisser</strong> correction under these
violations?</li>
</ul>
</div>
<div id="q2.-possibility-of-mediation-analysis-for-h3" class="section level4">
<h4>Q2. Possibility of Mediation Analysis for H3</h4>
<ul>
<li><strong>Independent variable structure:</strong> 4 <strong>equally
weighted</strong> types; there is no single “reference” type, so
standard dummy-coding with one baseline is not conceptually ideal.</li>
<li><strong>Design issue:</strong> All participants saw <strong>all four
types</strong> (repeated measures); classic mediation frameworks often
assume <strong>between-subjects</strong> manipulations.</li>
<li><strong>Current fallback:</strong> <strong>Simple
regressions</strong> testing whether <strong>perceived autonomy</strong>
significantly predicts <strong>behavioral intention</strong>,
<strong>interaction satisfaction</strong>, and <strong>reuse
intention</strong>.</li>
<li><strong>Question:</strong> Despite the within-subjects design and
four-level factor, is there a <strong>valid mediation approach</strong>
for H3?</li>
</ul>
</div>
<div id="q3-appropriate-analysis-for-manipulation-check-items-p.-8" class="section level4">
<h4>Q3 Appropriate Analysis for Manipulation-Check Items (p. 8)</h4>
<ul>
<li>Example (Type A): show that <strong>emotional appeal / gain
framing</strong> scores are <strong>high</strong>, whereas
<strong>rational appeal / loss framing</strong> scores are
<strong>low</strong>.</li>
<li><strong>Question:</strong> What statistical tests should be used to
demonstrate that the manipulations worked as intended?</li>
</ul>
</div>
<div id="q4.-balanced-latin-square-whether-an-independent-groups-design-is-preferable" class="section level4">
<h4>Q4. Balanced Latin Square &amp; Whether an Independent-Groups Design
Is Preferable</h4>
</div>
</div>
<div id="proposedconsidered-analysis-techniques" class="section level3">
<h3>3. Proposed/Considered Analysis Techniques</h3>
<ol style="list-style-type: decimal">
<li><strong>Repeated-Measures ANOVA</strong> (primary for H1/H2).</li>
<li><strong>Mediation analysis / Simple regression</strong> (for H3, as
feasible).</li>
</ol>
</div>
<div id="hypotheses" class="section level3">
<h3>4. Hypotheses</h3>
<ul>
<li><strong>H1:</strong> Do <strong>behavioral intention</strong>,
<strong>interaction satisfaction</strong>, and <strong>reuse
intention</strong> differ by <strong>persuasion type</strong>?</li>
<li><strong>H2:</strong> Does <strong>perceived autonomy</strong> differ
by <strong>persuasion type</strong>?</li>
<li><strong>H3 (Version 1 – Mediation):</strong> <strong>Perceived
autonomy</strong> mediates the relationship between <strong>persuasion
type</strong> and each outcome (<strong>behavioral intention</strong>,
<strong>interaction satisfaction</strong>, <strong>reuse
intention</strong>).</li>
<li><strong>H3 (Version 2 – Simple Regression):</strong> Within each
<strong>persuasion type</strong>, <strong>perceived autonomy</strong>
significantly predicts <strong>behavioral intention</strong>,
<strong>interaction satisfaction</strong>, and <strong>reuse
intention</strong>.</li>
</ul>
</div>
<div id="data-description" class="section level3">
<h3>5. Data Description</h3>
<ul>
<li><strong>N = 286</strong> survey respondents.</li>
<li><strong>Scales:</strong> 5-point Likert, multiple-choice
questionnaire items.</li>
<li><strong>Mediator:</strong> <strong>Perceived autonomy</strong>.</li>
<li><strong>Outcomes (DVs):</strong> <strong>Behavioral
intention</strong>, <strong>interaction satisfaction</strong>,
<strong>reuse intention</strong>.</li>
<li><strong>Independent variable (IV):</strong> <strong>Four persuasion
types</strong> (operationalized via image stimuli).</li>
</ul>
<hr />
</div>
</div>
<div id="ii.-answer-of-q1" class="section level2">
<h2>II. Answer of Q1</h2>
<div id="model" class="section level3">
<h3>1. Model</h3>
<p><strong>Conclusion:</strong> A <strong>one-way repeated-measures (RM)
ANOVA</strong> is the appropriate analysis.</p>
<ul>
<li><strong>Design:</strong> Within-subjects. All participants evaluated
<strong>four persuasion types</strong> (A, B, C, D).</li>
<li><strong>Dependent variables:</strong>
<ul>
<li>For <strong>H2</strong>: <em>Perceived autonomy</em><br />
</li>
<li>For <strong>H1</strong>: <em>Behavioral intention</em>,
<em>interaction satisfaction</em>, <em>reuse intention</em></li>
</ul></li>
<li>The <strong>same 286 participants</strong> experienced <strong>all
four conditions</strong> and provided repeated responses for the same
outcomes under each condition. Because observations are <strong>not
independent across conditions within participants</strong>, a
<strong>repeated-measures</strong> approach is required.</li>
</ul>
<p><strong>Model:</strong> <span class="math display">\[
Y_{ij} = \mu + \alpha_j + s_i + \epsilon_{ij}
\]</span> where <span class="math inline">\(Y_{ij}\)</span> is the
outcome for participant <span class="math inline">\(i\)</span> in
condition <span class="math inline">\(j\)</span>, <span class="math inline">\(\mu\)</span> is the grand mean, <span class="math inline">\(\alpha_j\)</span> is the fixed effect of
persuasion type <span class="math inline">\(j\)</span>, <span class="math inline">\(s_i\)</span> is the (random) subject effect, and
<span class="math inline">\(\epsilon_{ij}\)</span> is the residual.</p>
<p><strong>cf) Note on Two-Way Repeated-Measures ANOVA</strong> -
<strong>Technically feasible</strong>, but here the client <strong>did
not separate</strong> <em>appeal</em> (emotional vs. rational) and
<em>framing</em> (gain vs. loss) as two orthogonal factors.<br />
- Instead, these were <strong>combined into a single factor</strong>
(“persuasion type”).<br />
- Since the goal is to <strong>compare differences among the four
types</strong>, <strong>one-way RM ANOVA</strong> better matches the
research objective.</p>
</div>
<div id="normality" class="section level3">
<h3>2. Normality</h3>
<div id="kolmogorovsmirnov-ks-normality-test" class="section level4">
<h4>(1) Kolmogorov–Smirnov (K–S) Normality Test</h4>
<p><strong>Definition.</strong> Tests whether the sample empirical CDF
(ECDF) differs significantly from the CDF of a normal distribution.</p>
<ul>
<li>For sample <span class="math inline">\(X_1, X_2, \ldots,
X_n\)</span>, the ECDF is<br />
<span class="math display">\[
F_n(x) = \frac{1}{n}\sum_{i=1}^n \mathbf{1}(X_i \le x).
\]</span></li>
<li>Test statistic:<br />
<span class="math display">\[
D = \sup_x \lvert F_n(x) - F(x) \rvert,
\]</span> the maximum absolute gap between the ECDF and the target
normal CDF.</li>
<li>Hypotheses:<br />
<span class="math inline">\(H_0\)</span>: the sample follows a normal
distribution.<br />
<span class="math inline">\(H_1\)</span>: the sample does not follow a
normal distribution.</li>
<li>Decision rule: if <span class="math inline">\(p\)</span>-value <span class="math inline">\(&lt; 0.05\)</span>, reject <span class="math inline">\(H_0\)</span> (i.e., normality is violated).</li>
</ul>
<p><strong>Procedure</strong> 1. Compute the ECDF at each observation.
2. Compute the normal CDF (with appropriate mean/SD). 3. Compute <span class="math inline">\(D\)</span>. 4. Compare to the critical value (or
obtain a <span class="math inline">\(p\)</span>-value) at significance
level <span class="math inline">\(\alpha\)</span> and test <span class="math inline">\(H_0\)</span>.</p>
</div>
<div id="shapirowilk-normality-test" class="section level4">
<h4>(2) Shapiro–Wilk Normality Test</h4>
<p>For sample <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span>
(with order statistics <span class="math inline">\(x_{(1)} \le \cdots
\le x_{(n)}\)</span>), the statistic is <span class="math display">\[
W = \frac{\left(\sum_{i=1}^n a_i\, x_{(i)}\right)^2}{\sum_{i=1}^n (x_i -
\bar{x})^2},
\]</span> where <span class="math inline">\(a_i\)</span> are weights
derived under normality.</p>
<p><strong>Interpretation</strong></p>
<ul>
<li>Numerator: squared linear combination aligning observed order
statistics with those expected under normality.</li>
<li>Denominator: sample variance (total variation).</li>
<li><span class="math inline">\(W \approx 1\)</span> indicates strong
concordance with normality; smaller <span class="math inline">\(W\)</span> indicates departures from
normality.</li>
</ul>
<p><strong>Hypotheses</strong></p>
<ul>
<li><span class="math inline">\(H_0\)</span>: the sample follows a
normal distribution.</li>
<li><span class="math inline">\(H_1\)</span>: the sample does not follow
a normal distribution.<br />
Reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(p\)</span>-value <span class="math inline">\(&lt;
0.05\)</span>.</li>
</ul>
</div>
<div id="appropriateness-of-normality-testing-in-this-study" class="section level4">
<h4>(3) Appropriateness of Normality Testing in This Study</h4>
<p><strong>1) On averaging item scores within each
condition</strong></p>
<p>Averaging two items per condition can <strong>attenuate</strong>
non-normality. Therefore, it is preferable to test normality on the
<strong>original item-level scores</strong> rather than on the averaged
composites.</p>
<p><strong>2) Accounting for the repeated-measures
structure</strong></p>
<p>Because the design is <strong>within-subjects</strong>, measurements
are <strong>correlated</strong> across conditions (A/B/C/D). Testing
normality separately on each condition’s raw scores ignores this
correlation and can bias interpretation.</p>
<p>A more appropriate approach is to examine the
<strong>residuals</strong> from the repeated-measures model: <span class="math display">\[
Y_{ij} = \mu + \alpha_j + s_i + \epsilon_{ij},
\]</span> where <span class="math inline">\(\alpha_j\)</span> is the
fixed effect of condition <span class="math inline">\(j\)</span>, <span class="math inline">\(s_i\)</span> is the (random) subject effect, and
<span class="math inline">\(\epsilon_{ij} \sim
\mathcal{N}(0,\sigma^2)\)</span>.</p>
<ul>
<li>Pool <strong>all residuals across A, B, C, D</strong> and assess
their normality (e.g., Shapiro–Wilk or K–S on the residuals).</li>
<li><strong>Why not per-condition tests?</strong> The subject-specific
effect <span class="math inline">\(s_i\)</span> influences all
conditions; evaluating a single condition in isolation incompletely
accounts for this shared effect.</li>
</ul>
<p><strong>Visual diagnostics are recommended</strong> alongside tests
(e.g., QQ-plots of residuals).</p>
</div>
</div>
<div id="other-models-beyond-simple-one-way-anova" class="section level3">
<h3>3. Other Models (Beyond Simple One-Way ANOVA)</h3>
<div id="one-way-anova-between-subjects" class="section level4">
<h4>(1) One-Way ANOVA (Between-Subjects)</h4>
<ul>
<li>Appropriate when <strong>different participant groups</strong> each
experience <strong>only one condition</strong>.</li>
<li>Assumes <strong>independent observations</strong> across
groups.</li>
<li><strong>Not applicable here</strong> because all participants
experienced <strong>all four conditions</strong> (A/B/C/D).</li>
</ul>
</div>
<div id="repeated-measures-manova" class="section level4">
<h4>(2) Repeated-Measures MANOVA</h4>
<ul>
<li>Participants respond to <strong>multiple dependent
variables</strong> across <strong>multiple within-subject
conditions</strong> (e.g., A/B/C/D).</li>
<li>Analyzes <strong>several outcomes jointly</strong> (e.g., behavioral
intention, interaction satisfaction, reuse intention).</li>
<li>Useful when you want to test the <strong>common effect of
condition</strong> across <strong>correlated outcomes</strong>
simultaneously.
<ul>
<li>Example: If those three outcomes are correlated and you want to know
how they <strong>jointly</strong> change across A/B/C/D, RM-MANOVA is
appropriate.</li>
</ul></li>
</ul>
</div>
<div id="most-suitable-approach-for-this-study" class="section level4">
<h4>(3) Most Suitable Approach for This Study</h4>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Focus</th>
<th>Do we analyze correlations among DVs?</th>
<th>Recommended analysis</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Compare each DV separately across A/B/C/D</td>
<td><strong>No</strong> (no explicit need stated)</td>
<td><strong>Separate one-way RM ANOVA per DV</strong> (current approach
is appropriate)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="sphericity" class="section level3">
<h3>4. Sphericity</h3>
<ul>
<li><strong>Greenhouse–Geisser correction</strong> is a standard and
appropriate remedy when sphericity is violated.<br />
</li>
<li><strong>No issue</strong> using it in this context.</li>
</ul>
<hr />
</div>
</div>
<div id="iii.-answer-of-q2" class="section level2">
<h2>III. Answer of Q2</h2>
<div id="mediation-analysis" class="section level3">
<h3>1. Mediation Analysis</h3>
<p>Mediation analysis tests whether the effect of an independent
variable <code>X</code> on a dependent variable <code>Y</code> occurs
through a <strong>mediator <code>M</code></strong>.</p>
<p><strong>Structure:</strong></p>
<p>X (persuasion type) → M (perceived autonomy) → Y (behavioral
outcome)<br />
↘────────────────────────────────────────→ Y (direct path)</p>
<p>Key effects: - <strong>a path</strong>: <code>X → M</code> -
<strong>b path</strong>: <code>M → Y</code> (controlling for
<code>X</code>) - <strong>c’ path</strong>: <code>X → Y</code> (direct
effect) - <strong>Indirect effect</strong>: <code>a · b</code></p>
</div>
<div id="why-simple-regression-is-insufficient" class="section level3">
<h3>2. Why Simple Regression Is Insufficient</h3>
<p>The client proposes to:</p>
<ul>
<li>Run <strong>simple regressions</strong> within each persuasion type
(A, B, C, D) to test if <strong>perceived autonomy → behavioral
outcomes</strong> (behavioral intention, satisfaction, reuse
intention).</li>
</ul>
<p><strong>But this only examines the “b path” in
isolation.</strong><br />
It does not consider:</p>
<ul>
<li>The impact of persuasion type <code>X</code> on perceived autonomy
(<code>a</code> path)</li>
<li>Nor the full mediation structure</li>
<li>Nor the repeated-measures (within-subject) nature of the data</li>
</ul>
<p>Furthermore, regression assumes <strong>independence of
observations</strong>, which is violated here: the same participants
rated all 4 persuasion types.</p>
</div>
<div id="correct-method-repeated-measures-mediation-multilevel-mediation" class="section level3">
<h3>3. Correct Method: Repeated Measures Mediation (Multilevel
Mediation)</h3>
<p>Because the data involve:</p>
<ul>
<li><strong>All participants rating all 4 persuasion types</strong>
(within-subjects factor)</li>
<li><strong>Responses nested within participants</strong></li>
</ul>
<p>→ The correct approach is <strong>Multilevel Mediation
Analysis</strong> (also called Repeated Measures Mediation).</p>
</div>
<div id="model-structure" class="section level3">
<h3>4. Model Structure</h3>
<p><strong>Level 1 (within participants):</strong></p>
<p><span class="math display">\[\begin{aligned}
M_{ij} &amp;= \alpha_{0i} + a\,X_{ij} + r_{1ij} \\
Y_{ij} &amp;= \beta_{0i} + c&#39; \, X_{ij} + b \, M_{ij} + r_{2ij}
\end{aligned}\]</span></p>
<ul>
<li><span class="math inline">\(i\)</span>: participant<br />
</li>
<li><span class="math inline">\(j\)</span>: condition (A, B, C, D)</li>
</ul>
<p><strong>Level 2 (between participants):</strong></p>
<p><span class="math display">\[
\alpha_{0i} \sim \mathcal{N}(\gamma_{0}, \tau_{\alpha}^{2}), \quad
\beta_{0i} \sim \mathcal{N}(\delta_{0}, \tau_{\beta}^{2})
\]</span></p>
<p>→ This models both the fixed effects (mediation paths)
<strong>and</strong> random intercepts per participant.</p>
</div>
<div id="conclusion-key-message-for-client" class="section level3">
<h3>5. Conclusion (Key Message for Client)</h3>
<ul>
<li><strong>Yes, H3 mediation analysis <em>is possible</em></strong>
despite the repeated-measures design.</li>
<li>But it <strong>must be done</strong> using a <strong>Multilevel
Mediation model</strong> that accounts for the within-subject structure
of the data.</li>
<li>The simple regression approach may offer partial insight but
<strong>cannot test for mediation</strong> and violates statistical
assumptions (independence of residuals).</li>
<li>We strongly recommend using tools such as <code>lme4</code> and
<code>mediation</code> (or <code>brms</code> for Bayesian estimation) to
perform proper repeated-measures mediation.</li>
</ul>
<hr />
</div>
</div>
<div id="iv.-answer-of-q3" class="section level2">
<h2>IV. Answer of Q3</h2>
<div id="what-is-a-manipulation-check" class="section level3">
<h3>1. What is a Manipulation Check?</h3>
<p>A manipulation check verifies that the experimental manipulation (the
intended effect of the independent variable) was perceived by
participants as designed.<br />
Example: If you showed participants a <strong>“emotional
appeal”</strong> chatbot vs. a <strong>“rational appeal”</strong>
chatbot, you might ask, “How emotional was the chatbot you just saw?” (1
= not at all, 5 = very much).</p>
</div>
<div id="recommended-methods" class="section level3">
<h3>2. Recommended Methods</h3>
<div id="paired-dependent-t-tests" class="section level4">
<h4>(1) <strong>Paired (Dependent) t-tests</strong></h4>
<p>For <strong>each type</strong> (A, B, C, D), compare: -
<strong>Emotional</strong> vs <strong>Rational</strong> -
<strong>Gain</strong> vs <strong>Loss</strong></p>
<p>If, for a given type A, you find <strong>Emotional &gt;
Rational</strong> and <strong>Gain &gt; Loss</strong>, then the
manipulation for A is successful.</p>
<ul>
<li>First one-tailed test (Emotional vs Rational):<br />
<span class="math inline">\(H_0:\ \mu_{\text{Emo}} - \mu_{\text{Rat}} =
0\)</span><br />
<span class="math inline">\(H_1:\ \mu_{\text{Emo}} - \mu_{\text{Rat}}
&gt; 0\)</span></li>
<li>Second one-tailed test (Gain vs Loss):<br />
<span class="math inline">\(H_0:\ \mu_{\text{Gain}} - \mu_{\text{Loss}}
= 0\)</span><br />
<span class="math inline">\(H_1:\ \mu_{\text{Gain}} - \mu_{\text{Loss}}
&gt; 0\)</span></li>
</ul>
<p>Because the design <strong>predicts direction</strong> (Emotional
&gt; Rational; Gain &gt; Loss), <strong>one-tailed</strong> tests are
appropriate.</p>
<ul>
<li><strong>Multiplicity:</strong> There are <strong>8</strong> paired
t-tests total (2 contrasts × 4 types).<br />
Control the familywise error rate with <strong>Bonferroni</strong>: use
<span class="math inline">\(\alpha^* = 0.05/8\)</span> for each test (or
report adjusted <span class="math inline">\(p\)</span>-values).</li>
</ul>
</div>
<div id="one-way-repeated-measures-anova-within-a-type" class="section level4">
<h4>(2) <strong>One-Way Repeated-Measures ANOVA (within a
type)</strong></h4>
<p>Each participant provides Likert responses for all
<strong>four</strong> manipulation-check facets (<strong>Emotional,
Rational, Gain, Loss</strong>) → a within-subjects factor with 4 levels
is valid.</p>
<p>For a given type (e.g., A):</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{\text{Emo}} = \mu_{\text{Rat}} =
\mu_{\text{Gain}} = \mu_{\text{Loss}}\)</span><br />
</li>
<li><span class="math inline">\(H_1\)</span>: At least one mean
differs.</li>
</ul>
<p>If the ANOVA is significant (<span class="math inline">\(p &lt;
\alpha\)</span>), run <strong>pairwise comparisons</strong> (paired
t-tests) as <strong>post hoc</strong> to identify which pairs
differ.</p>
<ul>
<li>Number of pairs: <span class="math inline">\(\binom{4}{2} =
6\)</span>.<br />
</li>
<li>Apply a multiple-comparison correction (e.g., Bonferroni or
Holm).<br />
</li>
<li>Evidence of <strong>Emotional &gt; Rational</strong> and
<strong>Gain &gt; Loss</strong> indicates successful manipulation for
that type.</li>
</ul>
<blockquote>
<p>Most software (SPSS, R, etc.) can directly perform RM ANOVA and
<strong>post hoc paired comparisons</strong> with appropriate
adjustments.</p>
</blockquote>
</div>
</div>
<div id="non-normality-robust-alternatives" class="section level3">
<h3>3. Non-Normality: Robust Alternatives</h3>
<ul>
<li><strong>Paired t-test →</strong> <strong>Wilcoxon signed-rank
test</strong></li>
<li><strong>RM ANOVA →</strong> <strong>Friedman test</strong></li>
</ul>
<p>However, with <strong><span class="math inline">\(n=286\)</span></strong>, modest deviations from
normality are typically <strong>not consequential</strong> due to
large-sample robustness (CLT), especially for <strong>paired mean
differences</strong> and <strong>RM ANOVA residuals</strong>—provided
there are no extreme outliers or severe skewness. Complement tests with
<strong>QQ-plots</strong> and <strong>residual diagnostics</strong>.</p>
<hr />
</div>
</div>
<div id="v.-answer-of-q4" class="section level2">
<h2>V. Answer of Q4</h2>
<div id="appropriateness-of-a-balanced-latin-square" class="section level3">
<h3>1. Appropriateness of a Balanced Latin Square</h3>
<div id="example" class="section level4">
<h4>(1) Example</h4>
<p>A typical <strong>Balanced Latin Square</strong> for four
conditions:</p>
<table>
<thead>
<tr class="header">
<th>Order group</th>
<th>1st</th>
<th>2nd</th>
<th>3rd</th>
<th>4th</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Group 1</td>
<td>A</td>
<td>B</td>
<td>D</td>
<td>C</td>
</tr>
<tr class="even">
<td>Group 2</td>
<td>B</td>
<td>C</td>
<td>A</td>
<td>D</td>
</tr>
<tr class="odd">
<td>Group 3</td>
<td>C</td>
<td>D</td>
<td>B</td>
<td>A</td>
</tr>
<tr class="even">
<td>Group 4</td>
<td>D</td>
<td>A</td>
<td>C</td>
<td>B</td>
</tr>
</tbody>
</table>
<p>Each of A, B, C, D appears <strong>exactly once</strong> in each
serial position.</p>
</div>
<div id="is-it-suitable-re-minimizing-reviewer-concerns-about-order-effects" class="section level4">
<h4>(2) Is it suitable? (re: “minimizing reviewer concerns about order
effects”)</h4>
<ul>
<li>In within-subjects designs, a Balanced Latin Square is a
<strong>gold-standard method</strong> for order control—<strong>more
systematic</strong> than simple randomization.</li>
<li>In repeated-measures experiments, responses can depend on
presentation order (e.g., <strong>novelty/primacy</strong> for the first
stimulus; <strong>fatigue</strong> for the last). The balanced scheme
distributes such effects evenly across conditions.</li>
</ul>
</div>
<div id="must-group-sizes-be-identical" class="section level4">
<h4>(3) Must group sizes be identical?</h4>
<ul>
<li><strong>Not strictly.</strong> Minor imbalances (±1–2 participants)
are <strong>not problematic</strong>.</li>
<li>Large imbalances (e.g., <strong>50 vs 15</strong>) can distort
results; avoid pronounced disparities.</li>
</ul>
</div>
<div id="are-there-better-alternatives" class="section level4">
<h4>(4) Are there “better” alternatives?</h4>
<ul>
<li>For repeated-measures order control, the Balanced Latin Square is
already <strong>authoritative and appropriate</strong>.</li>
<li>Reporting that a Latin Square was used typically conveys
<strong>high design rigor</strong> to reviewers.</li>
</ul>
<p><strong>Sample size sufficiency</strong> - Minimum needed ≈
<strong>(# of orders) × (minimum per order)</strong>. - Here: <strong>4
orders</strong> and <strong>N = 286</strong>, i.e., about <strong>70 per
order</strong> → <strong>ample power</strong> and
<strong>validity</strong>.</p>
<p><strong>Optional model-based check for order effects</strong></p>
<p><span class="math display">\[
Y_{ijk} = \mu + \alpha_j + s_i + \gamma_k + \epsilon_{ijk}
\]</span></p>
<ul>
<li><span class="math inline">\(\alpha_j\)</span>: fixed effect of
condition <span class="math inline">\(j\)</span> (A/B/C/D)<br />
</li>
<li><span class="math inline">\(s_i\)</span>: random subject
effect<br />
</li>
<li><span class="math inline">\(\gamma_k\)</span>: fixed effect of
<strong>order group</strong> <span class="math inline">\(k=1,\dots,4\)</span></li>
</ul>
<p>If <span class="math inline">\(\gamma_k\)</span> is <strong>not
significant</strong>, order effects are negligible—evidence that the
Latin Square successfully controlled order.</p>
<blockquote>
<p>In short, the Latin Square is a <strong>validated</strong> method for
order control.</p>
</blockquote>
</div>
</div>
<div id="is-an-independent-groups-between-subjects-design-more-appropriate" class="section level3">
<h3>2. Is an Independent-Groups (Between-Subjects) Design More
Appropriate?</h3>
<div id="summary" class="section level4">
<h4>(1) Summary</h4>
<ol style="list-style-type: decimal">
<li><strong>Is the current repeated-measures design
appropriate?</strong> ✅ <strong>Yes—very appropriate</strong> and
aligned with the study goals.<br />
</li>
<li><strong>Would between-subjects be better?</strong> ❌
<strong>No—likely reduces accuracy</strong> (more noise from individual
differences).</li>
</ol>
</div>
<div id="side-by-side-comparison" class="section level4">
<h4>(2) Side-by-side comparison</h4>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Repeated-Measures (current)</th>
<th>Independent-Groups (alternative)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Statistical power</td>
<td>✅ <strong>Higher</strong> (shared variance removed)</td>
<td>❌ <strong>Lower</strong> (more error from individual
differences)</td>
</tr>
<tr class="even">
<td>Individual differences</td>
<td>✅ <strong>Controlled</strong> (same person rates all
conditions)</td>
<td>❌ <strong>Uncontrolled</strong></td>
</tr>
<tr class="odd">
<td>Order effects</td>
<td>⚠️ <strong>Potential</strong> → <strong>mitigate with Balanced Latin
Square</strong></td>
<td>✅ <strong>Absent by design</strong></td>
</tr>
<tr class="even">
<td>Fit to research aim (compare persuasion types)</td>
<td>✅ <strong>Excellent</strong></td>
<td>❌ Risk that group composition (traits) confounds condition
effects</td>
</tr>
</tbody>
</table>
</div>
<div id="answers-to-common-concerns" class="section level4">
<h4>(3) Answers to common concerns</h4>
<p><strong>“Isn’t it more valid to assign each condition to a different
random group?”</strong><br />
No. Individual differences can obscure or distort true condition
effects.<br />
Example: If Group A is more sensitive to emotional content and Group D
is less so, the outcomes may reflect <strong>participant
traits</strong>, not <strong>chatbot persuasion</strong>.</p>
<p><strong>“What about fatigue or order effects in repeated
measures?”</strong><br />
Valid concern, but <strong>Balanced Latin Square</strong> minimizes
order effects. Some fatigue may remain, but it’s a typical and
acceptable tradeoff for <strong>cleaner comparisons</strong>. Many
psychological experiments use repeated-measures for this reason.</p>
<p><strong>“Do we need to recollect data?”</strong><br />
<strong>Absolutely not.</strong> Your current design is
<strong>ideal</strong> for the research questions.</p>
</div>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

  </body>

  
</div>
