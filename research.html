---
layout: page
title: "Research"
permalink: /research/
---

{% include sidebar.html %}  <!-- ÏÇ¨Ïù¥ÎìúÎ∞î Ìè¨Ìï® -->

<div class="main-wrapper home-content" style="display: flex; align-items: flex-start;">

  <!-- ÏôºÏ™Ω Ïª¨Îüº: ÏÜåÍ∞ú -->
  <div class="intro-section" style="flex: 5;">

      <h1>1. Undergraduate</h1>
    <a href="https://github.com/jason1ko/EE-Capstone-Biometrics/raw/main/EE%20Capstone%20Final%20Report.pdf" target="_blank" rel="noopener noreferrer">EEE Capstone Final Report.pdf</a>
      <h2>Relative Embedding for Periocular and Face Recognition: Conditional Multimodal Biometrics</h2>

  <p>
    This <a href = https://github.com/jason1ko/EE-Capstone-Biometrics>repository</a> provides the implementation and experiments for the project
    <strong>"Relative Embedding for Periocular and Face Recognition: Conditional Multimodal Biometrics"</strong>,
    conducted at Yonsei University.
  </p>

  <hr>

  <h2>Motivation</h2>
  <p>
    The COVID-19 pandemic has reduced the accuracy of conventional face recognition because masks cover important facial areas.
    To address this, we focus on the <strong>periocular region</strong> (the area around the eyes) as a reliable biometric trait.
    We also propose a <strong>Conditional Multimodal Biometrics (CMB)</strong> framework that combines periocular and face
    recognition for stronger identification and verification.
  </p>

  <hr>

  <h2>Methodology</h2>

  <h3>End-to-End Deep Face Recognition</h3>
  <ul>
    <li><strong>Face Detection</strong>: Locate faces in images</li>
    <li><strong>Face Alignment</strong>: Normalize faces using key landmarks</li>
    <li><strong>Face Representation</strong>: Extract features with a MobileFaceNet backbone</li>
  </ul>

  <h3>Conditional Multimodal Biometrics (CMB)</h3>
  <ul>
    <li>Combines periocular and face embeddings</li>
    <li>
      Introduces a <strong>CMB Loss</strong> that:
      <ul>
        <li>Pulls embeddings from the same subject closer (even across modalities)</li>
        <li>Pushes embeddings from different subjects further apart</li>
      </ul>
    </li>
    <li>Supports four recognition tasks:
      <ul>
        <li>Periocular &harr; Periocular (p2p)</li>
        <li>Face &harr; Face (f2f)</li>
        <li>Periocular &harr; Face (p2f)</li>
        <li>Face &harr; Periocular (f2p)</li>
      </ul>
    </li>
  </ul>

  <h3>Similarity Metrics</h3>
  <ul>
    <li><strong>Cosine Similarity</strong> (main measure)</li>
    <li><strong>KL Divergence</strong> (tested for cross-modal similarity)</li>
  </ul>

  <hr>

  <h2>Software Implementation</h2>
  <ul>
    <li>Identification and verification pipelines using extracted embeddings</li>
    <li><strong>Metrics</strong>:
      <ul>
        <li>CMC (Cumulative Match Curve) for identification</li>
        <li>EER (Equal Error Rate), ROC, and AUC for verification</li>
      </ul>
    </li>
    <li>KL divergence optimized with broadcasting for faster computation</li>
  </ul>

  <hr>

  <h2>Datasets</h2>
  <p>Experiments were performed on six datasets:</p>
  <ul>
    <li><strong>Ethnic</strong></li>
    <li><strong>PubFig</strong></li>
    <li><strong>FaceScrub</strong></li>
    <li><strong>IMDB-Wiki</strong></li>
    <li><strong>AR</strong> (including blur, occlusion, and scarf conditions)</li>
    <li><strong>YTF (YouTube Faces)</strong></li>
  </ul>

  <hr>

  <h2>Results</h2>
  <ul>
    <li><strong>Periocular-to-Periocular</strong>: CMC up to ~97%, EER as low as 2.8%</li>
    <li><strong>Face-to-Face</strong>: CMC up to ~98%, EER ~2.4%</li>
    <li><strong>Cross-modal (p2f, f2p)</strong>: CMC up to ~97%, EER around 5%</li>
    <li><strong>YTF dataset</strong>: Lower performance due to low resolution</li>
  </ul>

  <p>Cosine similarity generally outperformed KL divergence.</p>
  <ul>
    <li>trained to separate identities using inner products</li>
    <li>scale-invariant, and robust to variations</li>
    <li>KL divergencer equires extra normalization, sensitive to small noisy components</li>
  </ul>

  <hr>

  <h2>Reference</h2>
  <p>
    This work is based on the graduation project submitted for EEE4610-01 at Yonsei University (Dec 2022).<br>
    Advisor: Prof. Andrew Beng Jin Teoh, Dr. Jae Woo Park.
  </p>



  <h1>2. Master</h1>
   <h2>Asymptotic Error and Regularization Path in High-Dimensional LDA: A Random Matrix Approach</h2>

    
  <p>
    This <a href = https://github.com/jason1ko/Master-s-Research-Paper-Thesis->repository</a> accompanies my master's research paper, which studies
    <strong>regularized discriminant analysis (rLDA)</strong> in the
    <strong>high-dimensional, low-sample-size (HDLSS)</strong> regime using tools from
    <strong>random matrix theory (RMT)</strong>.<br>
    It contains selected <strong>R codes</strong> that reproduce the theoretical derivations,
    numerical experiments, and figures presented in the paper.
  </p>

  <hr>

  <h2>üìò Paper Overview</h2>

  <p>
    <strong>Title:</strong> <em>Regularized Discriminant Analysis in the HDLSS Regime: A Random Matrix Perspective</em><br>
    <strong>Author:</strong> Han Jun Ko<br>
    <strong>Date:</strong> January 2025<br>
    <strong>Institution:</strong> Yonsei University, Department of Statistics
  </p>

  <h3>Abstract (Summary)</h3>

  <p>
    This work analyzes the asymptotic classification error of ridge-regularized LDA in the HDLSS regime.<br>
    We establish explicit limiting forms for the misclassification risk:
  </p>

  <p>
    <code>Err(\hat{w}_\lambda) \to \Phi(-\Theta(\lambda))</code>
  </p>

  <p>
    and provide theoretical and numerical characterization of the optimal regularization parameter
    Œª as a function of the aspect ratio Œ≥ = p/n and correlation strength œÅ in Toeplitz covariance
    structures (AR(1), Mat√©rn).
  </p>

  <hr>

  <h2>üßÆ Key Contributions</h2>

  <ol>
    <li>
      <strong>Closed-form limit under Œ£ = I</strong>
      <ul>
        <li>Derived a piecewise closed-form expression for the MDP limit Œò(0) across regimes Œ≥ &lt; 1, Œ≥ = 1, Œ≥ &gt; 1.</li>
        <li>Theoretical error curve Œ¶(‚àíŒò(0)) peaks at Œ≥ = 1, reconciling classical HDLSS observations.</li>
      </ul>
    </li>
    <li>
      <strong>Toeplitz Covariance Validation</strong>
      <ul>
        <li>Verified via <strong>Szeg≈ë‚Äôs theorem</strong> that AR(1) and Mat√©rn covariances satisfy RMT spectral assumptions.</li>
      </ul>
    </li>
    <li>
      <strong>Stable Approximation Pipeline</strong>
      <ul>
        <li>Implemented a numerically stable computation of Œò(Œª) using empirical spectral sums.</li>
        <li>Mapped <strong>Œª<sub>opt</sub>(Œ≥, œÅ)</strong> and analyzed the transition between MDP (Œª = 0) and MD (Œª = ‚àû).</li>
      </ul>
    </li>
  </ol>

  <hr>

  <h2>üß† Theoretical Framework</h2>

  <p>
    Regularized LDA forms a continuum between the <strong>Maximal Data Piling (MDP)</strong> and
    <strong>Mean Difference (MD)</strong> rules:
  </p>

  <p>
    <code>v(\lambda) = (CC^\top + \lambda I)^{-1} w, &nbsp; \lambda &gt; 0.</code>
  </p>

  <p>As Œª varies:</p>
  <ul>
    <li>Œª = 0 ‚Üí Maximal Data Piling (MDP)</li>
    <li>Œª = ‚àû ‚Üí Mean Difference (MD)</li>
    <li>Intermediate Œª ‚Üí Ridge-regularized direction connecting both ends</li>
  </ul>

  <p>
    The limiting misclassification risk depends on the
    <strong>Stieltjes transform</strong> of the sample covariance spectral distribution
    (Marchenko‚ÄìPastur law).
  </p>

  <hr>

  <h2>üìä Repository Contents</h2>

  <table border="1" cellpadding="6" cellspacing="0">
    <thead>
      <tr>
        <th>File</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><code>ar1_example.R</code></td>
        <td>plot of Œò(Œª), from Dobriban, E. &amp; Wager, S. (2018)</td>
      </tr>
      <tr>
        <td><code>rda_functions.R</code></td>
        <td>calculate Stieltjes functions, from Dobriban, E. &amp; Wager, S. (2018)</td>
      </tr>
      <tr>
        <td><code>rda_rcpp2.cpp</code></td>
        <td>generate multivariate Normal using Rcpp</td>
      </tr>
      <tr>
        <td><code>results.R</code></td>
        <td>includes all codes and functions needed for the paper</td>
      </tr>
    </tbody>
  </table>

  <hr>

  <h2>üîç Numerical Patterns Observed</h2>

  <ul>
    <li>Œª<sub>opt</sub> <strong>increases</strong> with Œ≥ and <strong>decreases</strong> with œÅ.</li>
    <li>Œò(Œª<sub>opt</sub>) is close to Œò(0) at small Œ≥ and approaches Œò(‚àû) as Œ≥ grows.</li>
    <li>
      Under Mat√©rn covariance, Œ¶(‚àíŒò(Œª<sub>opt</sub>)) and Œ¶(‚àíŒò(‚àû)) nearly coincide,
      indicating smoother effective regularization.
    </li>
  </ul>

  <hr>

  <h2>üîó Key References</h2>

  <ul>
    <li>
      Dobriban, E. &amp; Wager, S. (2018).
      High-dimensional asymptotics of prediction: Ridge regression and classification.
      <em>Annals of Statistics</em>.
    </li>
    <li>
      Ahn, J. &amp; Marron, J. S. (2010).
      The maximal data piling direction for discrimination.
      <em>Biometrika</em>.
    </li>
    <li>
      Lee, M. H., Ahn, J., &amp; Jeon, Y. (2013).
      HDLSS discrimination with adaptive data piling.
      <em>Journal of Computational and Graphical Statistics (JCGS)</em>.
    </li>
    <li>
      Bai, Z. &amp; Silverstein, J. (2010).
      <em>Spectral Analysis of Large Dimensional Random Matrices</em>. Springer.
    </li>
  </ul>

    

  </div>

  
  <!-- Ïò§Î•∏Ï™Ω Ïª¨Îüº: ÌîÑÎ°úÌïÑ -->
  <div class="profile-section" style="flex: 2; text-align: center;">
    {% include author-profile.html %}
  </div>

</div>
