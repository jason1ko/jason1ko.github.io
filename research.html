---
layout: page
title: "Research"
permalink: /research/
---

{% include sidebar.html %}  <!-- 사이드바 포함 -->

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']]
    }
  };
</script>
<script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>



<div class="main-wrapper home-content" style="display: flex; align-items: flex-start;">

  <!-- 왼쪽 컬럼: 소개 -->
  <div class="intro-section" style="flex: 5;">

      <h1>1. Undergraduate</h1>

    <p>
  In my undergraduate capstone project, I worked on a conditional multimodal biometrics system that combines periocular and full-face information to improve recognition performance when faces are partially occluded by masks or scarves. Using an end-to-end deep face recognition pipeline with MobileFaceNet-based embeddings, we extracted features from both periocular and face images and designed a framework that can flexibly handle periocular–periocular, face–face, and cross-modal matching.
</p>

<p>
  We compared cosine similarity and KL divergence as similarity measures and evaluated performance using CMC, EER, ROC, and AUC on several public datasets. The experiments showed that cosine similarity generally provided more stable and accurate verification, especially under cross-modal settings and low-quality images, confirming that periocular information can be a robust biometric cue when conventional face recognition degrades.
</p>

<p>
  You may download the final report <a href="{{ '/assets/files/EE Capstone Final Report.pdf' | relative_url }}" target="_blank" rel="noopener noreferrer">here</a>, or you may visit the relevant <a href = "https://github.com/jason1ko/EE-Capstone-Biometrics" target="_blank" rel="noopener noreferrer">Github repo</a> for more information.
</p>
    
<br><br><br><br>

  <h1>2. Master</h1>

<p>
  My master’s research studies ridge-regularized Linear Discriminant Analysis (rLDA) in a high-dimensional, low-sample-size regime using tools from random matrix theory. By viewing rLDA as a continuum between the maximal data piling (MDP) direction (no regularization) and the mean difference (MD) direction (infinite regularization), I analyze how the misclassification error behaves as the aspect ratio γ = p/n and the covariance structure vary, and how the optimal regularization parameter λ should be chosen.
</p>

<p>
  The work derives an explicit limit for the MDP case under identity covariance, explaining why error peaks around γ ≈ 1, and then extends the analysis to more realistic Toeplitz-type covariances such as AR(1) and Matérn that satisfy standard random-matrix assumptions. Using a numerically stable R implementation, I approximate the limiting error and map λ<sub>opt</sub>(γ, ρ), showing how the optimal classifier moves between MDP-like and MD-like behavior depending on dimensionality and correlation strength.
</p>

<p>
  You may download the final report <a href="{{ '/assets/files/Master's Research Report.pdf' | relative_url }}" target="_blank" rel="noopener noreferrer">here</a>, or you may visit the relevant <a href = "https://github.com/jason1ko/Master-s-Research-Paper-Thesis-" target="_blank" rel="noopener noreferrer">Github repo</a> for more information.
</p>
    

  </div>

  
  <!-- 오른쪽 컬럼: 프로필 -->
  <div class="profile-section" style="flex: 2; text-align: center;">
    {% include author-profile.html %}
  </div>

</div>
